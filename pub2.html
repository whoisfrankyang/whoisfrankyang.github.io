<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Quantifying Uncertainty in Modular Foundation Models | Bohan Yang</title>
  <meta name="author" content="Bohan Yang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <div class="container">
    <div style="margin-bottom: 30px;">
      <a href="index.html" style="color: #666; text-decoration: none; font-size: 14px;">← back to publications</a>
    </div>

    <div class="publication-detail-title">Quantifying Uncertainty in Modular Foundation Models: A Case Study in Robot-Assisted Bite Acquisition</div>
    <div class="publication-detail-authors"><strong>Bohan Yang</strong>, Rohan Banerjee, Krishna Palempalli, Sarah Dean, Tapomayukh Bhattacharjee</div>
    <div class="publication-detail-venue">ACM/IEEE International Conference on Human-Robot Interaction, Late-Breaking Reports (HRI LBR), 2026 (Under Review)</div>
    
    <div class="publication-detail-links" style="margin-top: 20px; margin-bottom: 30px;">
      <!-- Add links here when available -->
    </div>

    <div class="publication-detail-abstract">
      <div class="publication-detail-abstract-title">ABSTRACT</div>
      <div class="publication-detail-abstract-text">
        As robots increasingly rely on large foundation models for perception and planning, the ability to estimate uncertainty reliably on those foundation models becomes critical for safe human–robot interaction and effective human-in-the-loop failure recovery, particularly in assistive caregiving domains. While Vision–Language Models (VLMs) and Vision–Language–Action (VLA) models offer impressive generalization capabilities, they either lack native confidence measurements or produce uncalibrated scores prone to catastrophic overconfidence in failure modes. In this work, we introduce three model-specific uncertainty quantification strategies for a modular robotic bite-acquisition pipeline consisting of a food detector (GPT-4o), a bounding box selector (GroundingDINO), a skill selector (GPT-4o), and a skill parameter selector (RT-1). Leveraging data collected from full-pipeline food acquisition, we demonstrate that these tailored strategies substantially reduce overconfidence in failure modes compared to uncalibrated baselines. Our results highlight the necessity of architecture-specific uncertainty quantification to ensure safe and reliable failure recovery in foundation-model-based human–robot interaction systems.
      </div>
    </div>

    <div class="publication-detail-abstract" style="margin-top: 40px;">
      <div class="publication-detail-abstract-title">PAPER</div>
      <div style="margin-top: 20px; width: 100%;">
        <iframe 
          src="Quantifying_Uncertainty_in_Modular_Foundation_Models__A_Case_Study_in_Robot_Bite_Acquisition-3.pdf" 
          style="width: 100%; height: 800px; border: 1px solid #e0e0e0; border-radius: 4px;"
          type="application/pdf">
          <p>Your browser does not support PDFs. <a href="Quantifying_Uncertainty_in_Modular_Foundation_Models__A_Case_Study_in_Robot_Bite_Acquisition-3.pdf" target="_blank">Download the paper</a> instead.</p>
        </iframe>
      </div>
    </div>
  </div>
</body>

</html>

